{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Bias = Ability to understand the underlying predictive structure. Low bias means higher ability to understand the underlying structure and high bias means otherwise.\n",
    "\n",
    "Variance = Fittingness of model on training data. High variance means high dependence on the input training data and low variance means otherwise.\n",
    "\n",
    "In an ideal model, we aim for low bias-low variance. Ideal model should have high ability to uncover the underlying structure of the data and should produce results that are lowly dependent on the input training data. But this is often not attainable. We aim to minimize both but these both are inherently inversely proportional.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T02:18:09.787805Z",
     "start_time": "2020-09-12T02:18:09.250613Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from mlxtend.evaluate import bias_variance_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T02:18:09.986428Z",
     "start_time": "2020-09-12T02:18:09.788976Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset. This is boston housing dataset.\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "dataframe = read_csv(url, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T02:18:09.989830Z",
     "start_time": "2020-09-12T02:18:09.987659Z"
    }
   },
   "outputs": [],
   "source": [
    "# separate into inputs and outputs\n",
    "data = dataframe.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# from mlxtend.data import boston_housing_data, iris_data\n",
    "# X, y = iris_data() # Can be done on any data.\n",
    "# X, y = boston_housing_data() # This is same as the above url data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T02:18:10.003506Z",
     "start_time": "2020-09-12T02:18:09.990770Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T02:18:10.018332Z",
     "start_time": "2020-09-12T02:18:10.008534Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "modelLR = LinearRegression()\n",
    "modelDTR = DecisionTreeRegressor(random_state=5)\n",
    "modelBR = BaggingRegressor(base_estimator=modelDTR, n_estimators=100, random_state=245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T02:18:47.452646Z",
     "start_time": "2020-09-12T02:18:10.023784Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimate bias and variance\n",
    "# Linear Regression is simple model. It should have high bias but lower variance.\n",
    "mseLR, biasLR, varLR = bias_variance_decomp(modelLR, X_train, y_train, X_test, y_test, loss='mse', num_rounds=200, random_seed=1)\n",
    "# Decision Tree is a complex model. It should have low bias but high variance.\n",
    "mseDTR, biasDTR, varDTR = bias_variance_decomp(modelDTR, X_train, y_train, X_test, y_test, loss='mse', num_rounds=200, random_seed=5)\n",
    "# Bagging should have lower variance because it trains the base regressor on multiple random subsets of original dataset.\n",
    "mseBR, biasBR, varBR = bias_variance_decomp(modelBR, X_train, y_train, X_test, y_test, loss='mse', num_rounds=200, random_seed=245)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T02:18:47.456648Z",
     "start_time": "2020-09-12T02:18:47.453947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Linear Regression: MSE: 22.487, Bias: 20.726, Variance: 1.761\n",
      "For Decision Tree Regressor: MSE: 26.458, Bias: 9.774, Variance: 16.684\n",
      "For Bagging Regressor: MSE: 13.302, Bias: 10.242, Variance: 3.059\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print('For Linear Regression: MSE: %.3f, Bias: %.3f, Variance: %.3f' %(mseLR, biasLR, varLR))\n",
    "print('For Decision Tree Regressor: MSE: %.3f, Bias: %.3f, Variance: %.3f' %(mseDTR, biasDTR, varDTR))\n",
    "print('For Bagging Regressor: MSE: %.3f, Bias: %.3f, Variance: %.3f' %(mseBR, biasBR, varBR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
